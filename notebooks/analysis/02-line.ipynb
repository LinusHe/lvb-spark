{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, col, broadcast, avg, coalesce, lit, count\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import time\n",
    "import json\n",
    "\n",
    "%run \"/usr/local/spark/notebooks/00-spark-connection.ipynb\"\n",
    "\n",
    "# Optimize shuffle partitions based on your machine's cores\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"8\")  # Adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Read enriched departures from Parquet file\n",
    "df = spark.read.parquet(\"data/enriched_01.parquet\")\n",
    "print(f\"Loaded Parquet data in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Load line data\n",
    "# Read the JSON file as a regular text file\n",
    "start_time = time.time()\n",
    "with open(\"data/relevantLines_with_stops.json\", \"r\") as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create a list of rows\n",
    "rows = [(line_id, line_info['name'], line_info['product']) for line_id, line_info in json_data.items()]\n",
    "\n",
    "# Define the schema for the DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"line_id\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"product\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create the DataFrame\n",
    "lines_df = spark.createDataFrame(rows, schema)\n",
    "\n",
    "# Show the first few rows to verify\n",
    "lines_df.show(5)\n",
    "print(f\"Loaded line data in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Join the enriched departures with the line information\n",
    "start_time = time.time()\n",
    "joined_df = df.join(lines_df, df.lineId == lines_df.line_id, \"left\") \\\n",
    "    .select(df[\"*\"], \n",
    "            lines_df.name.alias(\"line_name\"), \n",
    "            lines_df.product.alias(\"line_product\"))\n",
    "joined_df.show(5)\n",
    "print(f\"Joined data in {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average delay grouped by product and collect example line names\n",
    "delay_by_product = joined_df.groupBy(\"line_product\") \\\n",
    "    .agg(F.avg(\"delay\").alias(\"avg_delay\"), \n",
    "         F.count(\"*\").alias(\"count\"),\n",
    "         F.collect_set(\"line_name\").alias(\"line_names\")) \\\n",
    "    .orderBy(F.desc(\"avg_delay\"))\n",
    "\n",
    "# Function to limit array to 5 elements and format as string\n",
    "def limit_and_format(arr):\n",
    "    limited = arr[:5]\n",
    "    return \", \".join(limited) + (\"...\" if len(arr) > 5 else \"\")\n",
    "\n",
    "# Register the UDF\n",
    "limit_and_format_udf = F.udf(limit_and_format, StringType())\n",
    "\n",
    "# Apply the UDF to the line_names column\n",
    "delay_by_product_with_examples = delay_by_product.withColumn(\n",
    "    \"example_lines\", \n",
    "    limit_and_format_udf(F.col(\"line_names\"))\n",
    ")\n",
    "\n",
    "# Show the results\n",
    "delay_by_product_with_examples.select(\n",
    "    \"line_product\", \n",
    "    F.round(\"avg_delay\", 2).alias(\"avg_delay\"), \n",
    "    \"count\", \n",
    "    \"example_lines\"\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge regional and suburban products\n",
    "merged_df = delay_by_product_with_examples.withColumn(\n",
    "    \"line_product\",\n",
    "    F.when(F.col(\"line_product\").isin([\"regional\", \"suburban\"]), \"suburban\")\n",
    "     .otherwise(F.col(\"line_product\"))\n",
    ")\n",
    "\n",
    "# Recalculate the aggregations with the merged products\n",
    "merged_delay_by_product = merged_df.groupBy(\"line_product\") \\\n",
    "    .agg(F.avg(\"avg_delay\").alias(\"avg_delay\"), \n",
    "         F.sum(\"count\").alias(\"count\"),\n",
    "         F.flatten(F.collect_list(\"line_names\")).alias(\"line_names\")) \\\n",
    "    .orderBy(F.desc(\"avg_delay\"))\n",
    "\n",
    "# Apply the UDF to the merged results\n",
    "merged_delay_with_examples = merged_delay_by_product.withColumn(\n",
    "    \"example_lines\", \n",
    "    limit_and_format_udf(F.col(\"line_names\"))\n",
    ")\n",
    "\n",
    "# Show the results with merged regional and suburban\n",
    "merged_delay_with_examples.select(\n",
    "    \"line_product\", \n",
    "    F.round(\"avg_delay\", 2).alias(\"avg_delay\"), \n",
    "    \"count\", \n",
    "    \"example_lines\"\n",
    ").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add count per day\n",
    "days_diff = (df.agg(F.max(\"plannedWhen\")).collect()[0][0] - df.agg(F.min(\"plannedWhen\")).collect()[0][0]).days + 1\n",
    "\n",
    "print(f\"Days diff: {days_diff}\")\n",
    "\n",
    "merged_delay_with_examples = merged_delay_with_examples.withColumn(\n",
    "    \"count_per_day\", \n",
    "    F.col(\"count\") / days_diff\n",
    ")\n",
    "\n",
    "# Show the results with count per day\n",
    "merged_delay_with_examples.select(\n",
    "    \"line_product\", \n",
    "    F.round(\"avg_delay\", 2).alias(\"avg_delay\"), \n",
    "    \"count\", \n",
    "    F.round(\"count_per_day\", 2).alias(\"count_per_day\"), \n",
    "    \"example_lines\"\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Spark DataFrame to Pandas DataFrame\n",
    "pdf = merged_delay_with_examples.select(\n",
    "    \"line_product\", \n",
    "    F.round(\"avg_delay\", 2).alias(\"avg_delay\"), \n",
    "    F.round(\"count_per_day\", 2).alias(\"count_per_day\")\n",
    ").toPandas()\n",
    "\n",
    "# Plotting\n",
    "fig, ax1 = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Add dashed y-grid\n",
    "ax1.yaxis.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Plot average delay on the primary y-axis\n",
    "bar_width = 0.35\n",
    "x = range(len(pdf['line_product']))\n",
    "ax1.bar([i - bar_width/2 for i in x], pdf['avg_delay'], width=bar_width, color='salmon', label='Avg Delay')\n",
    "ax1.set_xlabel('Line Product')\n",
    "ax1.set_ylabel('Average Delay (seconds)', color='salmon')\n",
    "ax1.tick_params(axis='y', labelcolor='salmon')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(pdf['line_product'])  # Use line products for x-axis labels\n",
    "\n",
    "# Create a second y-axis for count per day\n",
    "ax2 = ax1.twinx()\n",
    "ax2.bar([i + bar_width/2 for i in x], pdf['count_per_day'], width=bar_width, color='skyblue', label='Usage per Day')\n",
    "ax2.set_ylabel('Usage per Day', color='skyblue')\n",
    "ax2.tick_params(axis='y', labelcolor='skyblue')\n",
    "\n",
    "# Format y-axis labels to use commas as thousand separators\n",
    "def format_func(value, tick_number):\n",
    "    return f'{int(value):,}'\n",
    "\n",
    "ax2.yaxis.set_major_formatter(FuncFormatter(format_func))\n",
    "\n",
    "# Add legend\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "\n",
    "plt.title('Average Delay and Usage per Day by Line Product')\n",
    "\n",
    "# Rotate and align the tick labels so they look better\n",
    "plt.setp(ax1.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')\n",
    "\n",
    "# Adjust the subplot layout\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
